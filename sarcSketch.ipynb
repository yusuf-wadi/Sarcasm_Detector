{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Wow this note book thing is cool\n",
    "\n",
    "##### what am i doing <br>\n",
    "\n",
    "- who knows\n",
    "- all fee sabeel illah inshallah\n",
    "\n",
    "\n",
    "--------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Supervised Machine Learning*\n",
    "\n",
    "\n",
    "- Supervised learning refers to the method of ML that gives a neural model a data set and key, and from that <br>\n",
    "- It begins to make classifying predictions on novel data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<br>\n",
    "\n",
    "#### Lets see what data we're working with here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        article_link  \\\n",
      "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2  https://local.theonion.com/mom-starting-to-fea...   \n",
      "3  https://politics.theonion.com/boehner-just-wan...   \n",
      "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "\n",
      "                                            headline  is_sarcastic  \n",
      "0  former versace store clerk sues over secret 'b...             0  \n",
      "1  the 'roseanne' revival catches up to our thorn...             0  \n",
      "2  mom starting to fear son's web series closest ...             1  \n",
      "3  boehner just wants wife to listen, not come up...             1  \n",
      "4  j.k. rowling wishes snape happy birthday in th...             0  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(\"sarcastable.json\", lines=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"is_sarcastic\"] = data[\"is_sarcastic\"].map({0:\"Not_Sarcasm\", 1:\"Sarcasm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a data set that classifies article headlines as either sarcastic or not\n",
    "- from this data set, we will train a neural model to classify any text as either sarcasm or not.\n",
    "<br>\n",
    "----\n",
    "#### The data has now been classified, mapped to new values that are more readable.\n",
    "\n",
    " example below ‚¨áÔ∏è\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        article_link  \\\n",
      "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2  https://local.theonion.com/mom-starting-to-fea...   \n",
      "3  https://politics.theonion.com/boehner-just-wan...   \n",
      "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "\n",
      "                                            headline is_sarcastic  \n",
      "0  former versace store clerk sues over secret 'b...  Not_Sarcasm  \n",
      "1  the 'roseanne' revival catches up to our thorn...  Not_Sarcasm  \n",
      "2  mom starting to fear son's web series closest ...      Sarcasm  \n",
      "3  boehner just wants wife to listen, not come up...      Sarcasm  \n",
      "4  j.k. rowling wishes snape happy birthday in th...  Not_Sarcasm  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Now we reduce the data set to what we need, remove the link and such. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"headline\", \"is_sarcastic\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to set up the arrays using numpy ‚è¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headlines as x and sarcasm as y? is this necessary or haphazard\n",
    "#its essentially haphazard, but helps with understanding\n",
    "#no it is not haphazard. train_test_split syntax implies that training data is X and feedback is y\n",
    "\n",
    "x = np.array(data[\"headline\"])\n",
    "y = np.array(data[\"is_sarcastic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer \n",
    "\n",
    "- This tool from sklearn allows for the indexing of unique words from some text, and from this indexing,<br>\n",
    " a matrix of frequency for each word is formed. \n",
    " \n",
    " For example: ‚¨áÔ∏è<br><br>\n",
    "\n",
    "\n",
    "![picture 1](images/c633941a95c2c61ca9ffa09586da1448f0741266a0df5e6a8614b4c3ae4ade0d.png)  <br>\n",
    "\n",
    "- Each number on row[0] represents a unique word <br>\n",
    "\n",
    "- Each subsequent row represents a line of text, each words frequency encoded in the columns\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "- Now, we split the data into training and test constituents\n",
    "- the 0.2 represents a split of 20% testing data and 80% training\n",
    "- ((The test should then spit out a result regarding accuracy of the model))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "- Now we instantiate a Bernoulli Naive Bayes model, a neural model built on the Bayes' Theorem, shown below üîΩ <br>\n",
    "  \n",
    "![picture 4](images/0bb3a920cd4565ba5cbc511cbf9ca52b8bba15e62ade6a563a54d3c768d8dcc7.png)  \n",
    "\n",
    "- This model exceeds at classifying binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: \n",
      "0.8448146761512542\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model Accuracy: \")\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!<br>\n",
    "Now, we can try user input and classify it as sarcasm or otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not_Sarcasm']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Speak: \")\n",
    "data = cv.transform([user])\n",
    "out = model.predict(data)\n",
    "print(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa66cff0e5ae32d77d72462d7ae697218f766852b9c548e64c3db10232013247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
